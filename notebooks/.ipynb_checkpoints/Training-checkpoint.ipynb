{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data\n",
    "Take your data and upload to Cloudant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data into CSV\n",
    "The data in the database must be converted into a form that can be used to train the models for entity extraction and natural language classification. To do this, run the script below. Please edit the database connections so that they point to your database where all your data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cloudant\n",
    "import csv\n",
    "\n",
    "SERVER = 'https://1790ef54-fcf2-4029-9b73-9000dff88e6e-bluemix.cloudant.com' #Replace with your server URL\n",
    "DATABASE = 'amazon_data' #Replace with the name of the database\n",
    "USERNAME = '1790ef54-fcf2-4029-9b73-9000dff88e6e-bluemix' #Replace with the username from your credentials for the NLC\n",
    "PASSWORD = '5beb3f8b9f95586542e3d9c5acfb0c52832252432623e534d4e88b12fad29638' #Replace with the password from your credentials for the NLC\n",
    "DESIGN = '' #replace with the name of the design document that contains the view. This should be of the form '_design/XXXX'\n",
    "VIEW = 'names/namesAndAsin' #Replace with the view from your database to poll, this should take the form of view_file/view and should return the text to classify as the value field and what you would like to call it as the key\n",
    "DESTINATION = 'out.csv' #Replace with correct name for output file (NOTE must be *.csv)\n",
    "\n",
    "server = cloudant.client.Cloudant(USERNAME,PASSWORD,url=SERVER)\n",
    "server().connect\n",
    "db = server[DATABASE]\n",
    "query = db.get_view_result(DESIGN,VIEW)\n",
    "file = open(DESTINATION, 'wb')\n",
    "writer = csv.writer(file)\n",
    "\n",
    "\n",
    "for q in query:\n",
    "    print q[0]\n",
    "    if 'key' in q[0] and q[0]['key'] != None:\n",
    "        title = q[0]['key']\n",
    "    else:\n",
    "        title = \"No Title\"\n",
    "    if 'value' in q[0] and q[0]['value'] != None:\n",
    "        text = q[0]['value']\n",
    "    else:\n",
    "        text = \"No Text\"\n",
    "    writer.writerow([title,text])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data CSV into Watson Knowledge Studio\n",
    "The CSV that is created at the end of the script must now be imported into Watson Knowledge Studio (WKS). Each row in the CSV will be treated as a separate document and will be organized in WKS. The documents then need to be annotated with entities and relationships. Coreference is also done here. A strict guideline is very helpful when doing this.\n",
    "\n",
    "After the annotations are done and the model is trained, it needs to be exported into Alchemy Language using an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import token_replacement as t\n",
    "import csv\n",
    "\n",
    "read = open('ground_truth_layer1.csv','rb') ##replace with correct filenames\n",
    "write = open('ground_truth_layer1_replace.csv','wb')     ##replace with correct filenames\n",
    "\n",
    "reader = csv.reader(read)\n",
    "writer = csv.writer(write)\n",
    "\n",
    "for row in reader:\n",
    "    token = t.token_replacement(row[0])\n",
    "    writer.writerow([token,row[1]])\n",
    "\n",
    "read.close()\n",
    "write.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
